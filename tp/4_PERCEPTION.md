# ROS4PRO : JournÃ©e Perception
## Installation

ðŸ’»ðŸ“€  Pour effectuer cet atelier, vous devez installer quelques paquets. Pour cela,
positionnez vous Ã  la racine du dÃ©pÃ´t et exÃ©cutez la ligne suivante:
```
pip install -r requirements.txt
```

## Paquets et documentation

Pour effectuer ce travail, vous aurez besoin de manipuler majoritairement 4
bibliothÃ¨ques python de calcul scientifique:
+ _numpy_: Cette bibliothÃ¨que propose un tableau n-dimensionnel, ainsi que des
  opÃ©rations pour les manipuler. Ces opÃ©rations sont codÃ©es en C pour une 
  meilleure performance (python lui-mÃªme est trÃ©s lent). Ce tableau est __la__ 
  structure de donnÃ©e la plus importante pour le machine learning en python. 
  Dans notre cas, les images seront toujours encodÃ©es sous forme de tableau 
  numpy. Attention: Les tableaux numpy et les listes python sont des objets
  diffÃ©rents. Il arrive que dans le code, on doive passer de l'un Ã  l'autre.
  Faites bien attention Ã  garder en tÃªte le type de vos objets quand vous
  rÃ©flÃ©chissez Ã  votre code.
+ _scipy_: Cette bibliothÃ¨que propose un ensemble d'algorithme de calcul
  scientifique de base, rapides car souvent dÃ©veloppÃ©s en C Ã©galement. Scipy 
  utilise Ã©galement les tableaux numpy comme structure de donnÃ©e principale.
+ _scikit-image_: Cette bibliothÃ¨que propose un ensemble d'algorithmes de
  traitement d'images dÃ©veloppÃ©s en python (semblable Ã  `opencv`). Cette
  librairie contient beaucoup d'algorithmes, et nous en utiliserons certains.
  Notez que dans certains cas, les algorithmes peuvent Ãªtre assez lent Ã 
  exÃ©cuter. Dans ce cas, il peut Ãªtre intÃ©ressant de se tourner vers scipy si
  les mÃªmes algo sont disponibles.
+ _tensorflow-keras_: Cette bibliothÃ¨que propose un ensemble d'outils permettant de
  construire des rÃ©seaux de neurones. En outre, elle fait essentiellement deux
  choses: Elle permet de dÃ©river automatiquement le code de la passe backward
  Ã  partir du code de la passe forward, et elle permet d'exÃ©cuter ce code sur
  des ressources hÃ©tÃ©rogÃ¨nes comme des gpus, ou des grappes de calcul. Dans notre
  cas, nous n'utiliserons que les cpu. Depuis la version 2.0 (que nous
  utiliserons), tensorflow utilise Ã©galement des tableaux numpy comme structure
  de donnÃ©e.

Il existe de nombreuses ressources pour chacune de ces bibliothÃ¨ques, mais je vous
conseille de regarder celles ci si vous Ãªtes coincÃ©s:
+ [Numpy cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)
+ [Numpy Documentation](https://numpy.org/devdocs/user/quickstart.html)
+ [Scikit-Image Documentation](https://scikit-image.org/docs)
+ [Keras Documentation](https://keras.io/)
+ [Scipy ndimage documetation](https://docs.scipy.org/doc/scipy/reference/ndimage.html)

## 1. Partie DÃ©tection

Dans cette partie, vous allez dÃ©velopper et mettre au point un systÃ¨me de
dÃ©tection de cubes dans une image. A partir d'une image capturÃ©e par votre ergo,
telle que celle ci:

![img](img/12.png)

Vous devrez Ã©crire un programme permettant d'extraire une (ou plusieurs si
besoin) imagettes comme celle ci:

![img](img/sprite.png)

Ouvrez le fichier `src/detection.py`. Durant toute la durÃ©e du tp, vous 
devrez lancer le script en exÃ©cutant la ligne de commande:
```shell
$ python detection.py
```

Notez qu'Ã  tout moment, vous pouvez interrompre le script en appuyant sur 
`Ctrl-C` deux fois d'affilÃ©e. Il se peut Ã©galement qu'il faille fermer les
fenÃªtres encore ouverte pour que le programme se termine correctement.

En python, il n'existe pas de fonction `main` comme dans d'autre language. Dans
notre cas, le script dÃ©marre Ã  partir de la ligne suivante:
```python
#---------------------------- MAIN

if __name__ == "__main__":

    # Le script dÃ©marre son exÃ©cution iÃ§i.
    # ...
```

N'hÃ©sitez pas Ã  commenter les sections que vous avez dÃ©jÃ  effectuÃ© pour que le
script s'exÃ©cute plus vite Ã  chaque fois.

### 1.1 PrÃ©sentation des donnÃ©es

Le script commence par charger des donnÃ©es de test prÃ©alablement capturÃ©es, dans
un environnement contrÃ´lÃ©. Cependant, la fonction `show_image` qui permet
d'afficher ces images nÃ©cessite que vous remplissiez quelques fonctions, qui
manipulent des tableaux numpy.

> Remplissez les fonctions:
> + `get_image_min`
> + `get_image_max`
> + `get_image_shape`
> + `get_image_dtype`

Une fois ces fonctions remplies, vous pouvez dÃ©marrer le script. Les images
d'exemple devraient alors vous Ãªtre prÃ©sentÃ©es:

> RÃ©pondez aux questions suivantes:
> + Quelle est la forme du tableau? Ã€ quoi corresponde ces dimensions ?
> + Observez les valeurs minimales et maximales du tableau. Sont elles les mÃªmes
>   pour toutes les images? 
> + Quel est le type des donnÃ©es enregistrÃ©es dans le tableau numpy? Pourquoi
>   est-ce le cas? Ce type de donnÃ©e est il adaptÃ© aux rÃ©seaux de neurones? 
> + De maniÃ¨re gÃ©nÃ©rale, trouvez vous que la face des cubes est semblable aux 
>   images du dataset mnist que nous allons devoir utiliser pour
>   l'apprentissage? 

### 1.2 Segmentation de l'image

Maintenant, nous allons passer Ã  la segmentation de l'image. L'objectif de cette
Ã©tape est de dÃ©tecter, pour chacun des pixel, si il appartient Ã  un cube, ou si
il appartient au fond de la scÃ¨ne. Pour ce faire, nous allons utiliser une
approche classique nommÃ©e le __thresholding__. Les grandes Ã©tapes de
l'algorithme sont les suivantes:
+ On transforme l'image en niveaux de gris
+ On crÃ©e une image binaire grÃ¢ce Ã  une opÃ©ration de seuillage
+ On nettoie l'image binaire des artefacts du seuillage
+ On sÃ©pare les diffÃ©rentes zones blanches de l'image binaire
+ On nettoie chacune des zones blanches pour qu'elle se rapproche d'une face de
  cube blanc pleins.
  
Cet algorithme est contenu dans la fonction `segment_thresholding`, qui doit
renvoyer une liste d'images binaires contenant chacune le masque d'un des cubes
prÃ©sent sur l'image.

Observez la fonction `segment_thresholding`. La premiÃ¨re Ã©tape de la
segmentation consiste Ã  transformer l'image, jusqu'alors en couleurs, en une
image en niveaux de gris.

> Remplissez le code de la fonction `turn_to_grey`.
> RÃ©pondez aux questions suivantes: 
> + Pouvez vous penser Ã  plusieurs maniÃ¨re de transformer une image en RGB en
>   une image en niveaux de gris? 
> + Y a t il une diffÃ©rence Ã  utiliser une mÃ©thode en particulier.

Une fois la fonction remplie, l'exÃ©cution du script devrait montrer vos images
en noir et blanc.

> RÃ©pondez aux questions suivantes:
> + Quelle est la taille de l'image maintenant? 
> + Quels sont les valeurs maximales et minimales?
> + Quel est le type de donnÃ©e? Est il le mÃªme ou a t il changÃ©?

Nous allons Ã  prÃ©sent chercher Ã  sÃ©parer les pixels de l'image en deux
catÃ©gories, les pixels clairs (Ã  priori appartenant aux cubes) et les pixels
foncÃ©s (Ã  priori appartenant au fond). Pour cela, nous allons simplement
chercher une valeur _seuil_ (threshold en anglais) et sÃ©parer en deux les pixels
selon ce seuil. Il existe plusieurs maniÃ¨res de trouver le seuil optimal. Vous
pouvez le chercher Ã  la main, ou utiliser des algorithmes automatisÃ©s pour le
trouver. La librairie `scikit-image` contient plusieurs algorithmes de
seuillage. 

> Remplissez la fonction `compute_image_threshold` en essayant plusieurs 
> stratÃ©gies de thresholding.
> 
> RÃ©pondez aux questions suivantes:
> + Quelle stratÃ©gie avez vous essayÃ©? 
> + Voyez vous une diffÃ©rence entre les diffÃ©rentes stratÃ©gies? DÃ©taillez.
> + Quelle stratÃ©gie avez vous finalement choisie?

Lancez Ã  nouveau le programme. Vous devriez voir les images binarisÃ©es se 
prÃ©senter. 

> RÃ©pondez aux questions suivantes:
> + Quel est maintenant le type des donnÃ©es de l'image?
> + Observez ces diffÃ©rentes images. Les cubes sont ils entiÃ¨rement classifiÃ©s
>   comme tels ? Qu'en est il des Ã©critures se trouvant sur les faces?
> + La segmentation vous semble elle satisfaisante par rapport au problÃªme?

A la fin de l'algorithme chaque partie blanche contiguÃ« est sÃ©parÃ©e pour crÃ©er
un masque censÃ© couvrir un cube. 

> Observez attentivement les images issues de l'opÃ©ration de seuillage. Voyez
> vous des zones qui pourraient Ãªtre sÃ©parÃ©es alors qu'elles ne couvrent pas un
> cube entier ?

Pour amÃ©liorer cette Ã©bauche de segmentation, nous allons utiliser deux
opÃ©rations _morphologiques_ appelÃ©es _closing_ et _opening_.

> RÃ©pondez aux questions suivantes:
> + Quelle est la signification de ces opÃ©rations? DÃ©taillez.
> + En quoi pensez vous que ces opÃ©rations puissent amÃ©liorer notre 
>   segmentation?
> + Quelle est l'utilitÃ© du paramÃ¨tre de voisinage? Comment pensez vous pouvoir
>   le rÃ©gler?

Les librairies `scikit-image` et `scipy` contiennent toutes les deux des
implÃ©mentations de ces opÃ©rations. L'une est beaucoup plus rapide que l'autre.

> Remplissez les fonctions `perform_closing` et `perform_opening`.
> Essayez les fonctions des deux librairies susmentionnÃ©es.

> RÃ©pondez aux questions suivantes:
> + Quelle implÃ©mentations vous semble la plus rapide entre les deux?
> + Comment avez vous rÃ©glÃ© le paramÃ¨tre de voisinage? Quelle valeur avez vous
>   choisi? 

ExÃ©cutez le script a nouveau. Vous devriez voir les images binaires aprÃ¨s
nettoyÃ©es apparaÃ®tre. 

> RÃ©pondez aux questions suivantes:
> + Les dÃ©fauts de l'image binaire ont ils disparu?
> + La segmentation vous semble t elle satisfaisante?

Suite Ã  cela, l'algorithme utilise la fonction `ndimage.label` de `scipy` qui
sÃ©pare les diffÃ©rentes composantes contiguÃ«s d'une image binaire. Chaque
composante contiguÃ« est ensuite nettoyÃ© pour la phase suivante de l'algorithme
grÃ¢ce a la fonction `clean_shape`. A la sortie de cette fonction, l'image doit
Ãªtre parfaitement nettoyÃ©e, pour que la zone soit ne contienne aucune tache
sombre, et soit relativement lisse, comme sur cette image:

![img](img/clean_shape.png)

> Remplissez la fonction `clean_shape`. Quelles mÃ©thodes avez vous utilisÃ© pour
> nettoyer la forme? 

### 1.3 Recherche des contours

Pour continuer, nous devons transformer ces masques binaires en information
gÃ©omÃ©triques sur la position des coins du cube dans l'image. Pour faire cela,
nous allons utiliser un algorithme de dÃ©tection de contours.

La fonction `get_box_contours` contient la logique d'extraction des coins.
L'algorithme passe par les Ã©tapes suivantes, pour chacun des masques:
+ Un contour initial, contenant de nombreux points est gÃ©nÃ©rÃ©
+ Ce contour est simplifiÃ© pour ne garder que quatre Ã©lÃ©ments reprÃ©sentant les
  coins du cube.
  
La librairie `scikit-image` contient un algorithme permettant de chercher des
contours dans une image binaire.

> Remplissez la fonction `extract_raw_contour`

Le contour rÃ©cupÃ©rÃ© par la fonction `extract_raw_contour` contient un grand
nombre d'Ã©lÃ©ments. Cependant, pour la suite de notre algorithme, nous devons
pouvoir extraire les quatre coins de cet ensemble de points, pour ne garder
qu'eux.

> Remplissez la fonction `simplify_raw_contour`
> 
> RÃ©pondez aux questions suivantes: 
> + Quelles stratÃ©gie avez vous adoptÃ© pour extraire les coins? 
> + Relancez le script pour faire dÃ©filer quelques images dont les coins ont Ã©tÃ©
>   dÃ©tectÃ©s. Comment marche votre algorithme?

### 1.4 Extraction des vignettes

Maintenant que nous avons la position des coins, nous allons extraire de l'image
originale, des vignettes de la mÃªme taille que les images du dataset MNIST. Cela
permettra, dans la suite du tp, d'envoyer directement les imagettes au rÃ©seau de 
neurones pour que le label soit reconnu. Pour cela, nous allons effectuer une
transformation projective de la zone dÃ©limitÃ©e par les coin, en une image plate 
de 28 par 28 pixels.

> Repondez Ã  la question suivante:
> + Qu'est ce qu'une transformation projective?

La librairie contient une fonction permettant de calculer une transformation
projective Ã  partir des positions des points de dÃ©part et d'arrivÃ©e, et de
transporter l'image d'un espace Ã  l'autre. Cherchez dans la documentation cet
ensemble de fonctions.

> Remplissez les fonctions `compute_transform` et `transform_image`.

ExÃ©cutez le script, vous devriez voir dÃ©filer les images extraites. 

> Enregistrez quelques exemples d'imagettes extraites par votre algorithme.

Vous avez maintenant une vision complÃ¨te sur l'algorithme d'extraction des
imagettes. Dans le cours de ce matin, nous avons expliquÃ© que la pour crÃ©er un
tel programme, sans utiliser de donnÃ©es (ou trÃ©s peu), nous avons besoin de
faire des hypothÃ¨ses sur les donnÃ©es.

> Repondez aux questions suivantes:
> + Sur quelles hypothÃ¨ses est basÃ© l'algorithme d'extraction de vignettes? 
> + Dans les donnÃ©es d'essais dont nous disposons, arrive-t-il que ces
>   hypothÃ¨ses soient brisÃ©es?
> + Pouvez vous penser Ã  des situations dans laquelle notre robot pourrait se
>   trouver, qui briseraient Ã©galement ces hypothÃ¨ses?

Vous pouvez enregistrer votre fichier et le laisser tel quel pour le moment.

## 2. Challenge dÃ©tection

Pour l'instant notre algorithme est capable d'extraire les imagettes lorsque les
cubes sont sur un fond sombre. Ce n'est probablement pas le genre de scÃ¨ne dans
laquelle nous voulons faire Ã©voluer notre robot.

Toujours dans `detection.py` remplacez la ligne suivante:
```python
test_data = glob.glob('../data/ergo_cubes/dark/*.png')
```
par cette ligne:
```python
test_data = glob.glob('../data/ergo_cubes/challenge/*.png')
```

ExÃ©cutez le programme tel quel. Vous devriez voir s'afficher de nouvelles images
plus rÃ©alistes.

> RÃ©pondez aux questions suivantes:
> + Comment se dÃ©brouille l'algorithme sur ces nouvelles donnÃ©es ? 
> + Quelles hypothÃ¨ses prÃ©cÃ©dentes sont brisÃ©es par ces nouvelles donnÃ©es ?

Pendant ce challenge, vous allez dÃ©velopper un nouvel algorithme de segmentation
qui devrait avoir de meilleures performances sur ces images plus rÃ©alistes. Ã€ la
diffÃ©rence du prÃ©cÃ©dent algorithme qui n'exploitait que les niveaux de gris pour
segmenter l'image, nous allons maintenant utiliser un algorithme qui utilise la
couleur. 

L'algorithme va suivre les Ã©tapes suivantes:
+ Tout d'abord, l'image est segmentÃ©e en utilisant les images rgb
+ Cette segmentation est nettoyÃ©e pour faire disparaÃ®tre les artefacts de
  segmentation
+ Chaque objet de la segmentation est analysÃ© pour dÃ©terminer si oui ou non il
  correspond Ã  un cube.

### 2.1 ImplÃ©mentation

Commencez par remplacer les lignes suivantes de la partie _main_:
```python
for im in images:
    im = segment_thresholding(im, debug=True) 
...
for i, im in enumerate(images):
    ctrs.append(get_box_contours(im, segment_thresholding, debug=True))
...
```

Par les lignes suivantes:
```python
for im in images:
    im = segment_colors(im, debug=True) 
...
for i, im in enumerate(images):
    ctrs.append(get_box_contours(im, segment_colors, debug=True))
...
```

Maintenant, Ã  votre tour.

> Observez la fonction `segment_colors` et retrouvez la structure de
> l'algorithme prÃ©sentÃ© ci dessus. 
> 
> ImplÃ©mentez les fonctions `build_segmented_image`, `clean_shape` and
> `is_cube`. 
> 
> Dans un cours paragraphe, dÃ©taillez vos solutions, et les hypothÃ¨ses qu'elle
> exploite sur les donnÃ©es.
> 
> Une fois le programme aboutit, faite une video montrant votre algorithme en 
> fonctionnement sur les anciennes, ainsi que les nouvelles images, que vous 
> integrerez Ã  votre rendu.

## 3. Partie apprentissage

Nous allons maintenant nous intÃ©resser Ã  la partie rÃ©seaux de neurones
permettant d'extraire les labels Ã  partir des imagettes. Comme expliquÃ© ce matin
dans la prÃ©sentation, nous utiliserons le jeu de donnÃ©e _mnist_ pour entrainer
notre modÃ¨le. 

Commencez par ouvrir le fichier `learning.py`.

### 3.1 Chargement des donnÃ©es

Prenez connaissance du code, puis lancez le en exÃ©cutant Ã  la ligne de commande:
```
python learning.py
```
> Observez la fonction `load_data`, rÃ©pondez aux questions suivantes: 
> + Que contiennent les variables `x_train` et `y_train`?
> + Pourquoi la fonction `load_data` renvoie-t-elle Ã©galement les variables
>   `x_test` et `y_test`?
> + Quelles sont les formes respectives de `x_train` et `y_train`? 
> + Pouvez vous expliquer Ã  quoi correspondent chacune des dimensions de ces deux
>   tableaux?
> + Quelles sont les valeurs minimales et maximales de ces deux tableaux?
>   De quel type sont les donnÃ©es ? Expliquez.

### 3.2 PrÃ©-visualisation des donnÃ©es brutes

Appuyez sur entrÃ©e pour continuer, et observez les images. 

> RÃ©pondez aux questions suivantes:
> + Quelle sont les valeurs des pixels blancs (reprÃ©sentÃ©s en jaune) et des
>   pixels noirs? 
> + Observez bien les donnÃ©es et leurs labels. Toutes les images sont elles
>   simples Ã  classifier correctement? 
> + Ferriez vous des erreurs en les classifiant?

### 3.3 PrÃ©paration des donnÃ©es

Au dÃ©but de son entraÃ®nement, un rÃ©seau de neurones fonctionne bien lorsque les
donnÃ©es d'entrÃ©e sont centrÃ©es autour de 0 et ont un Ã©cart type de 1. Si ce
n'est pas le cas, les vecteurs de biais des diffÃ©rentes couches vont lentement
se modifier pour s'adapter aux donnÃ©es, mais cette Ã©tape est longue et gaspille
du temps de calcul inutilement. Il faut donc transformer nos donnÃ©es pour
qu'elles respectent ces prÃ©-requis.

De plus, la premiÃ¨re couche Ã©tant une couche de convolution, elle travaille
normalement avec des images ayant plusieurs canaux (RGB) encodÃ©s sur la derniÃ¨re
dimension du tableau, ce qui n'est pas le cas de notre jeu de donnÃ©e. Il faut
donc modifier la forme de votre tableau pour la rendre compatible avec
l'opÃ©ration de convolution.

> Remplissez la fonction `prepare_input`.

ExÃ©cutez le script. Vous devriez voir s'afficher le informations sur le tableau
prÃ©parÃ©.

> RÃ©pondez aux questions suivantes:
> + Quelle est la forme de `x_train` maintenant ?
> + Quelles sont les valeurs min et max ? Est ce que cela convient bien Ã  notre
>   prÃ©-requis?
> + Le type de donnÃ©e devrait avoir changÃ©? Quel est il? Sur quel type de donnÃ©e
>   pensez vous qu'un rÃ©seau de neurone travaille?

Il reste Ã  prÃ©parer les donnÃ©es de sortie. Pour l'instant, votre vecteur de
sortie `y_train` contient des entiers reprÃ©sentant le label de l'image.
Cependant pour fonctionner, notre rÃ©seau de neurones nÃ©cessite des donnÃ©es sous
la forme _one hot encoding_.

> RÃ©pondez aux questions suivantes:
> + Qu'est ce qu'un one-hot-encoding? En quoi est ce diffÃ©rent des donnÃ©es dont
>   nous disposons actuellement?
> + Observez la fonction `load_data`. A quoi sert la variable globale `CLASSES`?

> Remplissez la fonction `prepare_output`. RÃ©pondez aux questions suivantes:
> + Quelle est la forme de `y_train` maintenant ?
> + Quelles sont les valeurs min et max ? Est ce que cela convient bien Ã  notre
>   prÃ©-requis?

### 3.4 PrÃ©-visualisation des donnÃ©es prÃ©parÃ©es

ExÃ©cutez le script et observez les donnÃ©es prÃ©parÃ©es.
> RÃ©pondez aux questions suivantes:
> + Quelles sont les valeurs des pixels blanc et des pixels noirs maintenant?
> + Quelles sont les valeurs des labels maintenant ? Comprenez vous leur
>   signification sur cet exemple?

### 3.5 Le modÃ¨le

Maintenant, vous allez devoir dÃ©finir le modÃ¨le _LeNet5_ que nous avons vu
pendant le cours.

> Remplissez la fonction `build_model`.

ExÃ©cutez le script Ã  nouveau et observez le rÃ©sumÃ© du modÃ¨le. 

> RÃ©pondez aux questions suivantes:
> + Observez le nombre de paramÃ¨tres par couche. Quelles sont les couches qui
>   ont le plus grand nombre de paramÃ¨tres?
> + Cela vous semble t il normal ?
> + Qu'en concluez vous sur l'utilitÃ© des couches par convolution ? 

### 3.6 La fonction de coÃ»t et l'optimiseur

Durant la prÃ©sentation, nous avons vu que deux fonctions de coÃ»t sont
rÃ©guliÃ¨rement utilisÃ©es dans l'entraÃ®nement des rÃ©seaux de neurones:
+ L'erreur quadratique moyenne (Mean squared error)
+ L'entropie croisÃ©e (Cross entropy)

> Repondez Ã  la question suivante:
> + Quelle fonction de coÃ»t vous semble adaptÃ©e Ã  notre problÃ¨me ?
> 
> Remplissez la fonction `get_loss` pour implÃ©menter la fonction de coÃ»t
> adaptÃ©e. 

Pendant la prÃ©sentation, nous avons vu que l'optimiseur est l'algorithme qui
permet de se dÃ©placer sur la surface dessinÃ©e par la fonction de coÃ»t dans
l'espace des paramÃ¨tres. Cet algorithme permet de chercher l'endroit oÃ¹ la
fonction de coÃ»t est minimale. 

Un des algorithmes les plus simples s'appelle la __descente de gradient__ (GD)
et consiste Ã  se dÃ©placer dans le sens de la pente la plus forte Ã  chaque pas de
temps.

> RÃ©pondez aux questions suivantes:
> + Dans quelle hypothÃ¨se cet algorithme permet il de trouver le minimum global
>   de la fonction de coÃ»t selon vous ?
> + Pensez vous que cette hypothÃ¨se soit vÃ©rifiÃ©e pour les rÃ©seaux de neurones ?
> + Que se passe-t-il si cette hypothÃ¨se n'est pas vÃ©rifiÃ©e ? 

__Adam__ est un optimiseur plus complexe que GD. Sur l'image suivante, on voit
plusieurs optimiseurs se dÃ©placer sur une fonction de coÃ»t:

![cette image](https://github.com/Jaewan-Yun/optimizer-visualization/raw/master/figures/movie11.gif)

> RÃ©pondez Ã  la question suivante: 
> + Concentrez vous sur Adam et GD. Quelle semble Ãªtre la caractÃ©ristique de
>   Adam comparÃ©e a GD? 

Une autre caractÃ©ristique de l'algorithme GD, est que la taille du pas qui est
effectuÃ© Ã  chaque itÃ©ration est fixe. L'image suivante montre Adam et GD dans un
cas ou la pente devient trÃ©s forte:

![cette image](https://github.com/Jaewan-Yun/optimizer-visualization/raw/master/figures/movie9.gif)

> Repondez aux questions suivantes: 
> + GD arrive-t-il Ã  converger ? Comprenez vous pourquoi ?
> + Adam ne semble pas soumis au mÃªme problÃªme que GD ? Quelle autre
>   caractÃ©ristique de Adam cela montre t il? 
> + Quelle conclusion pouvez vous tirer sur l'utilitÃ© de GD pour entraÃ®ner des
>   rÃ©seaux de neurones ?

Maintenant Ã  vous de jouer.

> Remplissez la fonction `get_optimizer`.

### 3.7 Entrainement

Relancez le code et appuyez sur entrÃ©e jusqu'au dÃ©clenchement de la partie 3.7.
Vous devriez voir les itÃ©rations d'entraÃ®nement se succÃ©der.

> RÃ©pondez aux questions suivantes:
> + Observez l'Ã©volution de la prÃ©cision sur l'ensemble d'entraÃ®nement et
>   l'ensemble de test. Les valeurs sont elles identiques ?
> + Ã€ partir de combien d'Ã©poques le rÃ©seau est il entraÃ®nÃ© selon vous ?
> + En rÃ©glant le nombre d'itÃ©ration d'apprentissage dans le code (argument
>   `epochs` de la fonction fit), arrivez vous Ã  observer une phase de
>   sur-apprentissage ?

### 3.8 Poids appris

Appuyez sur entrÃ©e pour visualiser les noyaux appris par le rÃ©seau de neurones. 

> RÃ©pondez aux questions suivantes:
> + En observant les noyaux de la premiÃ¨re couche, arrivez vous Ã  distinguer le
>   genre de features qui seront extraites par chacun des noyaux?
> + Pouvez vous en faire de mÃªme pour la deuxiÃ¨me couche ?

### 3.9 Activations

Appuyez sur entrÃ©e, puis rentrez un indice (un entier de n'importe quelle valeur
infÃ©rieure a 5000).

> RÃ©pondez aux questions suivantes:
> + AprÃ¨s la premiÃ¨re couche de convolution, les features extraites
>   correspondent elles Ã  celles que vous imaginiez ?
> + AprÃ¨s la premiÃ¨re couche de pooling, les features prÃ©sentes auparavant sont
>   elles conservÃ©es ?
> + AprÃ¨s la deuxiÃ¨me couche de pooling, diriez vous que de l'information
>   spatiale est toujours prÃ©sente ? Autrement dit, les activations ressemblent
>   elles toujours Ã  des images ?

### 3.10 Entrainement final

ArrÃªtez le script en appuyant sur `ctrl+c`. Jusqu'Ã  prÃ©sent, nous avons
travaillÃ© sur l'ensemble des donnÃ©es, mais pour la suite nous n'aurons besoin
que des images de 1 et de 2. Changez la valeur de la variable `CLASSES` pour ne
garder que les classes qui nous intÃ©ressent, entraÃ®nez en rÃ©seau, puis
sauvegardez le dans un fichier.

## 4. IntÃ©gration

Il est maintenant temps d'intÃ©grer les deux parties du pipeline pour
l'utilisation finale. Ouvrez le fichier `main.py` Ã  la racine du projet. Pour
que les deux parties du pipeline s'adaptent correctement, il faut que les
vignettes renvoyÃ©es par la partie dÃ©tection ressemblent aux images du dataset
mnist (dans leur valeurs, leur type, etc).

> Remplissez la fonction `preprocess`.

Une fois que cela est fait, exÃ©cutez le script. Vous devriez pouvoir examiner la
performance de votre algorithme complet sur les images de test.

> RÃ©pondez aux questions suivantes:
> + Quelles sont les performances de l'algorithme global?
> + Observez vous des sources de bugs dans l'algorithme?

Enfin, en vous connectant Ã  l'ergo, rÃ©cupÃ©rez quelque images des cubes dans
votre propre environnement, puis dÃ©posez les dans `data/ergo_cubes/perso`.
Lancez le programme et observez la performance de votre algorithme sur les
donnÃ©es de votre propre environnement.

> RÃ©pondez aux questions suivantes:
> + Quelles sont les performances de l'algorithme sur vos donnÃ©es ? 
> + Sont elles comparables aux performances sur les exemples dont nous
>   disposons? 

Nous avons vu que le sur-apprentissage est une des difficultÃ©s les plus
importantes dans l'utilisation des algorithmes d'apprentissage. Lorsque vous
avez rÃ©glÃ© votre programme de dÃ©tection, vous l'avez fait en utilisant
l'ensemble des donnÃ©es dont vous disposiez, sans garder de groupe test sÃ©parÃ©.
Cette maniÃ¨re de faire peut Ã©galement mener Ã  du sur-apprentissage, mais cette
fois, de votre part, dans le rÃ©glage de votre algorithme. Le sur-apprentissage
n'est donc pas rÃ©servÃ© aux algorithmes mais est plutÃ´t une des difficultÃ©s de la
programmation basÃ©e sur les donnÃ©es. Que ce soit un humain ou un programme, le
rÃ©glage de paramÃ¨tres en fonction de donnÃ©es connaÃ®t les mÃªmes dÃ©fauts.

De maniÃ¨re gÃ©nÃ©rale, il est futile d'attendre de ce type de programme qu'il
extrapole Ã  des donnÃ©es (des situations) qui n'ont pas Ã©tÃ© prÃ©sentÃ©es pendant
l'apprentissage. Il est donc important, lors du dÃ©veloppement de ce type de
programme, de prÃ©voir une phase de rÃ©colte de donnÃ©e importante, dont on
s'assure qu'elle couvrira bien les usages futures du programme.
